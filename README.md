# Deep-Learning-On-Medical-Image
Paper LIst about Deep Learning on Medical Image

## Brain Tumor Segmentation 

### Review

- [x] [Multimodal Brain MRI Tumor Segmentation via Convolutional Neural Networks]()  (2017,   **\*\*\***)

> Glioma are the most common family of brain tumors, with a subset of glioma known as glioblastoma forming the most common and some of the highest-mortality and economically costly forms of brain cancer. Patients are diagnosed based on manual segmentation and analysis of multimodal MRI scans, but due to the labor-intensive nature of the manual segmentation process and mistakes or disagreement between manual segmentations, there exists a need for a fast and robust automated segmentation algorithm. Convolutional neural networks (CNNs) have been shown to be extremely effective for a variety of visual recognition and semantic segmentation tasks. Here, we present three
> novel CNN-based architectures for glioma segmentation for images from the MICCAI BraTS Challenge dataset. We also explore transfer learning between the BraTS dataset and other neuroimaging datasets by applying models pretrained on the BraTS dataset to segmenting images from the Rembrandt dataset. Our results show that patch-wise approaches trained on a balanced training set of tumor and non-tumor patches delivers strong segmentation results with mean dice score of 0.86. The results from transfer learning show that applying models pre-trained on the BraTS dataset to other neuroimaging datasets is promising but requires further work.

- [x] [The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)](http://ieeexplore.ieee.org/abstract/document/6975210/)  (2015, **\*\*\*\*\***)

> In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients - manually annotated by up to four raters - and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.

- [ ] [Glioma Dynamics and Computational Models: A Review of Segmentation, Registration, and In Silico Growth Algorithms and their Clinical Applications](http://www.ingentaconnect.com/content/ben/cmir/2007/00000003/00000004/art00007)  (2007, **\*\***)

> Tracking gliomas dynamics on MRI has became more and more important for therapeutic management. Powerful computational tools have been recently developed in this context enabling in silico growth on a virtual brain that can be matched with real 3D segmented evolution through registration between atlases and patient brain MRI data. In this paper, we provide an extensive review of existing algorithms for the three computational tasks involved in patient-specific tumor modeling: image segmentation, image registration, and in silico growth modelling (with special emphasis on the proliferation-diffusion model). Accuracy and limits of the reviewed algorithms are systematically discussed. Finally applications of these methods for both clinical practice and fundamental research are also discussed. 

- [ ] [A survey of MRI-based medical image analysis for brain tumor studies](https://www.researchgate.net/publication/237070108_A_survey_of_MRI-based_medical_image_analysis_for_brain_tumor_studies) (2013, **\*\*\***) 

>MRI-based medical image analysis for brain tumor studies is gaining attention in recent times due to an increased need for efficient and objective evaluation of large amounts of data. While the pioneering approaches applying automated methods for the analysis of brain tumor images date back almost two decades, the current methods are becoming more mature and coming closer to routine clinical application. This review aims to provide a comprehensive overview by giving a brief introduction to brain tumors and imaging of brain tumors first. Then, we review the state of the art in segmentation, registration and modeling related to tumor-bearing brain images with a focus on gliomas. The objective in the segmentation is outlining the tumor including its sub-compartments and surrounding tissues, while the main challenge in registration and modeling is the handling of morphological changes caused by the tumor. The qualities of different approaches are discussed with a focus on methods that can be applied on standard clinical imaging protocols. Finally, a critical assessment of the current state is performed and future developments and trends are addressed, giving special attention to recent developments in radiological tumor assessment guidelines. 

### Generative Models

- [ ] K. Van Leemput, F. Maes, D. Vandermeulen, P. Suetens, "Automated model-based bias field correction of MR images of the brain", *IEEE Trans. Med. Imag.*, vol. 18, no. 10, pp. 885-896, Oct. 1999.  
- [ ] M. R. Kaus, S. K. Warfield, A. Nabavi, P. M. Black, F. A. Jolesz, R. Kikinis, "Automated segmentation of MR images of brain tumors", *Radiology*, vol. 218, no. 2, pp. 586-591, Feb. 2001.
- [ ] M. Prastawa, E. Bullitt, S. Ho, G. Gerig, "A brain tumor segmentation framework based on outlier detection", *Med. Image Anal.*, vol. 8, pp. 275-283, 2004.
- [ ] K. M. Pohl, J. Fisher, J. J. Levitt, M. E. Shenton, R. Kikinis, W. E. L. Grimson, W. M. Wells, "A unifying approach to registration segmentation and intensity correction", *Proc. MICCAI*, pp. 310-318, 2005
- [ ] F. O. Kaster, B. H. Menze, M.-A. Weber, F. A. Hamprecht, "Comparative validation of graphical models for learning tumor segmentations from noisy manual annotations", *Proc. MICCAI-MCV*, 2010.
- [ ] B. Fischl, "Whole brain segmentation: Automated labeling of neuroanatomical structures in the human brain", *Neuron.*, vol. 33, no. 3, pp. 341-355, 2002
- [ ] J. Ashburner, K. J. Friston, "Unified segmentation", *Neuroimage*, vol. 26, no. 3, pp. 839-851, 2005.
- [ ] A. Gooya, "GLISTR: Glioma image segmentation and registration", *IEEE Trans. Med. Imag.*, vol. 31, no. 10, pp. 1941-1954, Oct. 2012.

### Discriminative Models

- [ ] [D. Cobzas, N. Birkbeck, M. Schmidt, M. Jagersand, A. Murtha, "3D variational brain tumor segmentation using a high dimensional feature set", *Proc. ICCV*, pp. 1-8, 2007.](http://ieeexplore.ieee.org/document/4409130/)  (2007, **\*\***)
- [ ] [S. Ho, E. Bullitt, G. Gerig, "Level-set evolution with region competition: Automatic 3D segmentation of brain tumors", Proc. ICPR, pp. 532-535, 2002.](http://ieeexplore.ieee.org/document/1044788) (2002, **\*\***)
- [ ] [C. Lee, S. Wang, A. Murtha, R. Greiner, "Segmenting brain tumors using pseudo conditional random fields", Proc. MICCAI, pp. 359-366, 2008.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiMt6KjuvTWAhVFYo8KHQefAVAQFgguMAE&url=https%3A%2F%2Fwebdocs.cs.ualberta.ca%2F~btap%2FPapers%2FChihoon_MICCAI_2008.pdf&usg=AOvVaw0p2lAIDa7wjKiGVZqIRGAo)  (2008, **\*\***)
- [ ] [S. Bauer, L.-P. Nolte, M. Reyes, "Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization", Proc. MICCAI, pp. 354-361, 2011.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwjwjr6nu_TWAhUFtI8KHf8VAbQQFggxMAI&url=http%3A%2F%2Fftp.mauricioreyes.me%2FPublications%2FBauerMiccai2011.pdf&usg=AOvVaw3GVzM3HAks9pcF6nZGMVI2) (2011, **\*\***)
- [ ] [W. Wu, A. Y. Chen, L. Zhao, J. J. Corso, "Brain tumor detection and segmentation in a conditional random fields framework with pixel-pairwise affinity and superpixel-level features", Int. J. Comput. Assist. Radiol. Surg., pp. 1-13, 2013.]()  (2013, **\*\***)

### CNN-Based Models

- [x] [Fully Convolutional Networks for Semantic Segmentation](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html) (2015, **\*\*\*\***)

> Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.

- [FCN-presentation]() 
- [FCN Codes](https://github.com/LoserSun/fcn.berkeleyvision.org) 




- [ ] [Automatic Detection of Cerebral Microbleeds from MR Images via 3D Convolutional Neural Networks](http://appsrv.cse.cuhk.edu.hk/~qdou/cmb-3dcnn/cmb-3dcnn.html)


> Cerebral microbleeds (CMBs) are small haemorrhages nearby blood vessels. They have been recognized as important diagnostic biomarkers for many cerebrovascular diseases and cognitive dysfunctions. In current clinical routine, CMBs are manually labelled by radiologists but this procedure is laborious, time-consuming, and error prone. In this paper, we propose a novel automatic method to detect CMBs from magnetic resonance (MR) images by exploiting the 3D convolutional neural network (CNN). Compared with previous methods that employed either low-level hand-crafted descriptors or 2D CNNs, our method can take full advantage of spatial contextual information in MR volumes to extract more representative high-level features for CMBs, and hence achieve a much better detection accuracy. To further improve the detection performance while reducing the computational cost, we propose a cascaded framework under 3D CNNs for the task of CMB detection. We first exploit a 3D fully convolutional network (FCN) strategy to retrieve the candidates with high probabilities of being CMBs, and then apply a well-trained 3D CNN discrimination model to distinguish CMBs from hard mimics. Compared with traditional sliding window strategy, the proposed 3D FCN strategy can remove massive redundant computations and dramatically speed up the detection process. We constructed a large dataset with 320 volumetric MR scans and performed extensive experiments to validate the proposed method, which achieved a high sensitivity of 93.16% with an average number of 2.74 false positives per subject, outperforming previous methods using low-level descriptors or 2D CNNs by a significant margin. The proposed method, in principle, can be adapted to other biomarker detection tasks from volumetric medical data.

- [x] [Brain tumor segmentation with Deep Neural Networks](http://www.sciencedirect.com/science/article/pii/S1361841516300330)
> In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we’ve found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.
>
> We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.

- [ ] [VoxResNet: Deep Voxelwise Residual Networks for Volumetric Brain Segmentation.]()

> Segmentation of key brain tissues from 3D medical images is of great significance for brain disease diagnosis, progression assessment and monitoring of neurologic conditions. While manual segmentation is time-consuming, laborious, and subjective, automated segmentation is quite challenging due to the complicated anatomical environment of brain and the large variations of brain tissues. We propose a novel voxelwise residual network (VoxResNet) with a set of effective training schemes to cope with this challenging problem. The main merit of residual learning is that it can alleviate the degradation problem when training a deep network so that the performance gains achieved by increasing the network depth can be fully leveraged. With this technique, our VoxResNet is built with 25 layers, and hence can generate more representative features to deal with the large variations of brain tissues than its rivals using hand-crafted features or shallower networks. In order to effectively train such a deep network with limited training data for brain segmentation, we seamlessly integrate multi-modality and multi-level contextual information into our network, so that the complementary information of different modalities can be harnessed and features of different scales can be exploited. Furthermore, an auto-context version of the VoxResNet is proposed by combining the low-level image appearance features, implicit shape information, and high-level context together for further improving the segmentation performance. Extensive experiments on the well-known benchmark (i.e., MRBrainS) of brain segmentation from 3D magnetic resonance (MR) images corroborated the efficacy of the proposed VoxResNet. Our method achieved the first place in the challenge out of 37 competitors including several state-of-the-art brain segmentation methods. Our method is inherently general and can be readily applied as a powerful tool to many brain-related studies, where accurate segmentation of brain structures is critical.



- [ ]  [Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images](http://ieeexplore.ieee.org/document/7426413/)

> Among brain tumors, gliomas are the most common and aggressive, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of oncological patients. Magnetic resonance imaging (MRI) is a widely used imaging technique to assess these tumors, but the large amount of data produced by MRI prevents manual segmentation in a reasonable time, limiting the use of precise quantitative measurements in the clinical practice. So, automatic and reliable segmentation methods are required; however, the large spatial and structural variability among brain tumors make automatic segmentation a challenging problem. In this paper, we propose an automatic segmentation method based on Convolutional Neural Networks (CNN), exploring small 3 ×3 kernels. The use of small kernels allows designing a deeper architecture, besides having a positive effect against overfitting, given the fewer number of weights in the network. We also investigated the use of intensity normalization as a pre-processing step, which though not common in CNN-based segmentation methods, proved together with data augmentation to be very effective for brain tumor segmentation in MRI images. Our proposal was validated in the Brain Tumor Segmentation Challenge 2013 database (BRATS 2013), obtaining simultaneously the first position for the complete, core, and enhancing regions in Dice Similarity Coefficient metric (0.88, 0.83, 0.77) for the Challenge data set. Also, it obtained the overall first position by the online evaluation platform. We also participated in the on-site BRATS 2015 Challenge using the same model, obtaining the second place, with Dice Similarity Coefficient metric of 0.78, 0.65, and 0.75 for the complete, core, and enhancing regions, respectively.



## MICCAI 2017

- [ ] [Transfer Learning for Domain Adaptation in MRI: Application in Brain Lesion Segmentation](http://arxiv.org/abs/1702.07841v1) (2017, **\*\*\*\***)

> Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis and treatment. However, variations in MRI acquisition protocols result in different appearances of normal and diseased tissue in the images. Convolutional neural networks (CNNs), which have shown to be successful in many medical image analysis tasks, are typically sensitive to the variations in imaging protocols. Therefore, in many cases, networks trained on data acquired with one MRI protocol, do not perform satisfactorily on data acquired with different protocols. This limits the use of models trained with large annotated legacy datasets on a new dataset with a different domain which is often a recurring situation in clinical settings. In this study, we aim to answer the following central questions regarding domain adaptation in medical image analysis: Given a fitted legacy model, 1) How much data from the new domain is required for a decent adaptation of the original network?; and, 2) What portion of the pre-trained model parameters should be retrained given a certain number of the new domain training samples? To address these questions, we conducted extensive experiments in white matter hyperintensity segmentation task. We trained a CNN on legacy MR images of brain and evaluated the performance of the domain-adapted network on the same task with images from a different domain. We then compared the performance of the model to the surrogate scenarios where either the same trained network is used or a new network is trained from scratch on the new dataset.The domain-adapted network tuned only by two training examples achieved a Dice score of 0.63 substantially outperforming a similar network trained on the same set of examples from scratch.

## Others



- [x] [Low-dose CT denoising with convolutional neural network](http://arxiv.org/abs/1610.00321v1)  

> To reduce the potential radiation risk, low-dose CT has attracted much attention. However, simply lowering the radiation dose will lead to significant deterioration of the image quality. In this paper, we propose a noise reduction method for low-dose CT via deep neural network without accessing original projection data. A deep convolutional neural network is trained to transform low-dose CT images towards normal-dose CT images, patch by patch. Visual and quantitative evaluation demonstrates a competing performance of the proposed method.

